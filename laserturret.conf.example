# Laser Turret Configuration File
# Copy this file to laserturret.conf and adjust values for your setup

[GPIO]
# Limit switch GPIO pins (BCM numbering)
x_ccw_limit_pin = 21
x_cw_limit_pin = 18
y_ccw_limit_pin = 4
y_cw_limit_pin = 20

[MQTT]
# MQTT broker configuration for remote control
broker = localhost
port = 1883
topic = laserturret

[Motor]
# X-axis motor pins
x_dir_pin = 19
x_step_pin = 23
x_enable_pin = 5

# Y-axis motor pins
y_dir_pin = 26
y_step_pin = 24
y_enable_pin = 6

# Microstepping pins (shared between both motors)
ms1_pin = 17
ms2_pin = 27
ms3_pin = 22

# Motor specifications
microsteps = 8          # Microstepping resolution (1, 2, 4, 8, or 16)
steps_per_rev = 200     # Steps per revolution (typically 200 for 1.8Â° motors)

[Control]
# Maximum steps to move per MQTT message
max_steps_per_update = 50

# Values between -deadzone and +deadzone are ignored (reduces jitter)
deadzone = 5

# Speed scaling factor (lower = slower, higher = faster)
speed_scaling = 0.10

# Delay between steps in seconds (lower = faster, but may skip steps)
step_delay = 0.0005
idle_timeout_sec = 120.0

[Laser]
# Laser control pin (BCM numbering)
laser_pin = 12

# Maximum laser power percentage (0-100)
laser_max_power = 100

[Camera]
# Camera resolution
width = 1920
height = 1080

# Camera format (RGB888, YUV420, etc.)
format = RGB888

# Number of camera buffers
buffer_count = 2

[Detection]
# Object detection method: 'haar', 'tflite', or 'roboflow'
# haar: Fast, simple, works for faces/bodies (legacy, lower accuracy)
# tflite: Slower but more accurate, detects 80+ object classes (local inference)
# roboflow: Uses remote Roboflow Inference Server for custom trained models
detection_method = haar

# TensorFlow Lite model (only used if detection_method = tflite)
# Available models: 'ssd_mobilenet_v2', 'efficientdet_lite0'
tflite_model = ssd_mobilenet_v2

# Use Coral USB Accelerator for TFLite inference (requires Coral hardware)
use_coral = false

# Confidence threshold for TFLite detections (0.0-1.0)
# Higher = fewer false positives, lower = more detections
tflite_confidence = 0.5

# Classes to detect with TFLite (comma-separated, empty = all classes)
# Example: person,cat,dog,bird
# See COCO_LABELS in tflite_detector.py for full list
tflite_filter_classes =

# Roboflow Inference Server settings (only used if detection_method = roboflow)
# URL of the Roboflow Inference Server (running on another machine or localhost)
# Default port is 9001. Use 0.0.0.0 in docker-compose to allow network access.
# Example: http://192.168.1.100:9001
roboflow_server_url = http://localhost:9001

# Roboflow model ID in format: workspace/project/version
# Example: myteam/balloon-detection/1
# Get this from your Roboflow project dashboard
roboflow_model_id = 

# Roboflow API key (optional, only needed for private models or hosted inference)
# Leave empty if using a self-hosted inference server with public models
roboflow_api_key = 

# Confidence threshold for Roboflow detections (0.0-1.0)
# Higher = fewer false positives, lower = more detections
roboflow_confidence = 0.5

# Classes to detect with Roboflow (comma-separated, empty = all classes)
# Example: balloon
roboflow_class_filter = 

# Balloon detection (HSV + shape-based), used when Detection Mode = balloon (Haar method)
# HSV Value (brightness) threshold for "black" mask (0-255). Lower = darker.
balloon_v_threshold = 60

# Minimum contour area in pixels
balloon_min_area = 2000

# Minimum circularity (0.0-1.0), higher is more round
balloon_circularity_min = 0.55

# Minimum fill ratio (area / bounding-box area)
balloon_fill_ratio_min = 0.5

# Allowed aspect ratio range (w/h)
balloon_aspect_ratio_min = 0.6
balloon_aspect_ratio_max = 1.6
